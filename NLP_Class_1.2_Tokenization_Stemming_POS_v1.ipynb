{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class 1 Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Stemming & Lemmatization, Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "#nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! pip install --user textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4 |Anaconda 4.0.0 (64-bit)| (default, Aug 14 2017, 13:41:13) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flu', 'season', 'hitting', 'earlier', ',', 'with', 'dozens', 'more', 'outbreaks', '—', 'and', 'more', 'severe', 'symptoms']\n"
     ]
    }
   ],
   "source": [
    "text = \"Flu season hitting earlier, with dozens more outbreaks — and more severe symptoms\"\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'C://Users//Nick//Documents//Teaching//Data Projects//Text//Books//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = '3boat10.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7778 samples and 79620 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 5702),\n",
       " ('the', 3338),\n",
       " ('and', 3215),\n",
       " ('.', 3081),\n",
       " ('to', 1748),\n",
       " ('a', 1621),\n",
       " ('of', 1425),\n",
       " ('I', 1208),\n",
       " ('it', 1159),\n",
       " ('in', 931)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(directory+book)\n",
    "bk_3boat = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent clean words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6232 samples and 29826 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 378),\n",
       " ('would', 362),\n",
       " ('harris', 316),\n",
       " ('george', 308),\n",
       " ('one', 246),\n",
       " ('us', 228),\n",
       " ('boat', 186),\n",
       " ('get', 179),\n",
       " ('could', 175),\n",
       " ('got', 163)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "#words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have to instantiate a Text object first, and then call it on that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textList = Text(nltk.corpus.gutenberg.words(directory+book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A concordance view shows us every occurrence of a given word, together with some context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 199 matches:\n",
      "                                     BOAT ( TO SAY NOTHING OF THE DOG ). Three\n",
      "                                     Boat by Jerome K . Jerome CHAPTER I . THR\n",
      "ty of people very bad indeed , whole boat - loads of them ; but I never met a \n",
      " like a fellow I saw on the Yarmouth boat one day , I could account for the se\n",
      "ckles I ever tasted in a respectable boat . Did you have any ?\" For myself , I\n",
      "eep , you get fooling about with the boat , and slop me overboard . If you ask\n",
      "o down in the morning , and take the boat up to Chertsey , and George , who wo\n",
      "n stillness . Then we run our little boat into some quiet nook , and the tent \n",
      "talk , the river , playing round the boat , prattles strange old tales and sec\n",
      "is a good two inches of water in the boat , and all the things are damp . You \n",
      "rd man , who has been baling out the boat , and who has spilled the water down\n",
      "uld not allow of the navigation of a boat sufficiently large to take the thing\n",
      "eople , on that voyage , load up the boat till it is ever in danger of swampin\n",
      " ! Throw it overboard . It makes the boat so heavy to pull , you nearly faint \n",
      "row the lumber over , man ! Let your boat of life be light , packed with only \n",
      " dangerous thing . You will find the boat easier to pull then , and it will no\n",
      " suggested George ; \" we will have a boat with a cover . It is ever so much si\n",
      "ean . You fix iron hoops up over the boat , and stretch a huge canvas over the\n",
      " stem to stern , and it converts the boat into a sort of little house , and it\n",
      "it was so pleasant to wake up in the boat in the fresh morning , and plunge in\n",
      "ave Harris clean and fresh about the boat , even if we did have to take a few \n",
      "ooze . We kept it in the nose of the boat , and , from there , it oozed down t\n",
      " the rudder , impregnating the whole boat and everything in it on its way , an\n",
      "away from it at Marlow . We left the boat by the bridge , and took a walk thro\n",
      "r to take paraffine oil with us in a boat again - except , of course , in case\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 31 matches:\n",
      "                                      DOG ). Three Men in a Boat by Jerome K . \n",
      "ed up at me , and think : \" Oh , that dog will never live . He will be snatched\n",
      "t door but one for having a ferocious dog at large , that had kept him pinned u\n",
      "e and someone to love you , a cat , a dog , and a pipe or two , enough to eat a\n",
      "ed him . I didn ' t encourage him . A dog like that don ' t want any encouragem\n",
      " with eggs and bacon , irritating the dog , or flirting with the slavey , inste\n",
      "dly . He would take bronchitis in the dog - days , and have hay - fever at Chri\n",
      "by the lady of the house ? That china dog that ornaments the bedroom of my furn\n",
      "my furnished lodgings . It is a white dog . Its eyes blue . Its nose is a delic\n",
      "me it is more than probable that that dog will be dug up from somewhere or othe\n",
      "s age , do not see the beauty of that dog . We are too familiar with it . It is\n",
      "o our eyes . So it is with that china dog . In 2288 people will gush over it . \n",
      " one another , and we beamed upon the dog , too . We loved each other , we love\n",
      "INE TO DRINK THE RIVER . - A PEACEFUL DOG . - STRANGE DISAPPEARANCE OF HARRIS A\n",
      "life , with care . I do not blame the dog ( contenting myself , as a rule , wit\n",
      "but mangy about the middle ; a bull - dog , a few Lowther Arcade sort of animal\n",
      "chained up there , between the bull - dog and the poodle . He sat and looked ab\n",
      "d dignified . He looked at the bull - dog , sleeping dreamlessly on his right .\n",
      "his own place , and caught the bull - dog by the ear , and tried to throw him a\n",
      "ed to throw him away ; and the bull - dog , a curiously impartial animal , went\n",
      "d , and snatched up that sweet little dog of hers ( he had laid the tyke up for\n",
      "have chilled the heart of the boldest dog . He stopped abruptly , and looked ba\n",
      "' s boy , with basket . Long - haired dog . Cheesemonger ' s boy , with basket \n",
      "owards us on the sluggish current , a dog . It was one of the quietest and peac\n",
      "dogs I have ever seen . I never met a dog who seemed more contented - more easy\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"similar\" helps us discover what other words appear in a similar range of contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river man time thing water night day lock bank way things morning boy\n",
      "air business kettle room matter city sail\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit trout long morning dream party change widow man body fee dim\n",
      "sudden heap time fellow cover timeyfied map splutter\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional information helps determine the location of a word in the text: how many words from the beginning it appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG0FJREFUeJzt3XuYJHV97/H3R1e5LWFVNoqKO97vupFRwSC7ivGKRp8Q\nxWgEnxjUY/KEGIzyYNwh0RgvMXpijLco3oNyNIdDzFGjQSOIMosgKOIlLOIFWaIroB5F/J4/qpqp\nbbpnemZ6dnrX9+t55pnqql/9ft+q6u5Pd3VPTaoKSdKvtputdgGSpNVnGEiSDANJkmEgScIwkCRh\nGEiSMAw0QZL8W5Jjl9nHcUk+u8w+vpxk83L6GKdx7JcljDmT5L27ckytLsNAS5JkW5JHjbPPqnpc\nVb1rnH12JZlKUkmua3++n+TMJL/VV8d9q+qslapjsVZqvyQ5NcnP233xgySfSHKvJfQz9vuCdj3D\nQL+K1lXVWuCBwCeAjyQ5brWKSbJmtcYGXt3uizsCVwGnrmItWkWGgcYuyVFJLkiyI8k5SR7Qzr9r\n+wr0Qe3t2yfZ3jslk+SsJM/p9POHSS5Jcm2Sr3TWe0mSb3bmP2UpdVbVlVX1BmAGeFWSm7X93/hK\nN8lDkswmuaZ9J/G6dn7vXcbxSb6b5HtJTuzUfrNOnf+d5INJbt237h8k+RbwqSR7J3lv23ZHkvOS\n3LZ/v7T9vjTJ5UmuSvLuJAf09Xtskm8luTrJySPui58A7wfuN2h5kie1p892tPXcu53/HuBOwP9p\n32H8+WKPgyaDYaCxSvIbwDuA5wK3Ad4CnJFkr6r6JvBi4L1J9gXeCbxr0CmZJL9L8yT9LODXgCcB\n/90u/ibwcOAA4JS2v4OWUfaHgV8H7jlg2RuAN1TVrwF3BT7Yt/wRwN2BRwMv7pwu+WPgycAm4PbA\nD4F/6Ft3E3Bv4DHAse32HEyz354H/HRAPce1P48A7gKsBd7Y1+bwdluOBF7We+KeT5K1wDOALw5Y\ndg/gA8AJwHrgozRP/resqt8HvgU8sarWVtWrFxpLk8kw0LgdD7ylqj5fVTe057p/BhwKUFVvA74B\nfB44CBj2yvU5NKcwzqvGN6rq8raPD1XVd6vql1V1GvB14CHLqPm77e9bD1h2PXC3JAdW1XVVdW7f\n8lOq6sdVdRFNuD29nf884OSq+nZV/Ywm2I7uOyU0067703ac2wB3a/fb1qq6ZkA9zwBeV1X/VVXX\nAScBx/T1e0pV/bSqLgQupDkdNsyJSXbQHJO1NEHT72nAv1bVJ6rqeuC1wD7Aw+bpV7sZw0DjtgH4\ns/Z0wo72ieZgmlfHPW+jOR3x9+0T5SAH07wDuIkkz+qchtrR9nXgMmq+Q/v7BwOW/QFwD+Cr7amb\no/qWX9GZvpy57dxA81lEr8ZLgBuA2w5Z9z3Ax4B/bk87vTrJLQbUc/t2nO6Ya/r6vbIz/ROaJ/lh\nXltV66rqdlX1pPbd27xjVtUv29rvMKCtdlOGgcbtCuAV7RNM72ffqvoA3Hg64vXAPwEzvfPoQ/q5\na//MJBtowuSPgNtU1TrgYiDLqPkpNB+eXtq/oKq+XlVPpzmN9Crg9CT7dZoc3Jm+E3PvMq4AHte3\nH/auqu90u++Mc31VnVJV96F5xX0UzSmyft+lCZrumL8Avj/iti7FTmMmCc1297bFSx/vAQwDLcct\n2g8+ez9raJ6on5fkoWnsl+QJSfZv13kDMFtVzwH+FXjzkL7fTnMK45C2n7u1QbAfzZPPdoAkz2bI\nh54LSXLbJH8EbAFOal/x9rd5ZpL17bId7exuu79Ism+S+wLPBk5r578ZeEVbM0nWJ/nteWp5RJL7\nJ7k5cA3NaaOb1ENz7v5Pk9y5Dda/Bk6rql8sZtsX6YPAE5Ic2b5b+TOaU3/ntMu/T/P5hXZjhoGW\n46M0H3L2fmaqahb4Q5oPNX9Icy76OID2yfCxwPPb9V8IPCjJM/o7rqoPAa+g+YbLtcC/ALeuqq8A\nfwt8juZJ6P7A2Yuse0eSHwMXAY8Hfreq3jGk7WOBLye5jibIjmnP8fd8ut3GT9Kccvl4O/8NwBnA\nx5NcC5wLPHSemm4HnE4TBJe0/b5nQLt3tPM/A1wG/D+aD6tXTFVdCjwT+HvgauCJNB8Y/7xt8krg\npe0psROHdKMJF/+5jbR4SaZonoxvscKvyqVdwncGkiTDQJLkaSJJEr4zkCTR/LHKbuHAAw+sqamp\n1S5DknYrW7duvbqq1i/UbrcJg6mpKWZnZ1e7DEnarSS5fOFWniaSJGEYSJIwDCRJGAaSJAwDSRKG\ngSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIk\nDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwk\nSRgGkiQMA0kShoEkCcNAksQSwyBhKuHi5Q6ecFzC7Zfbz0I2b4aZmWZ6Zqb52bx5bnlv3mL73LwZ\npqZu2jc087tj7ArdbVjs9iy0Tndb1q3beZsX6m9qavG1zDd+t//eGJs3w5o1ze2b3Wzudu8Y9Y7X\nsD5695HufWPY/uwe81F07wujrLeUY9cdp387+u//o4zdv0+WUtuwx1V/Pd26u+v2jl3/uuvW7Xxc\n5xu/t05/2+U+Vrr19PoY9DzTX8fMTHO/nJqa245uX4PW2VXPI6mqxa8UpoAzq7jfsgYPZwEnVjG7\nUNvp6emanV2w2bBxAKiam+7d7l++2D67fQ0aZwm7d8mSnbdpsWPPt05/3zC3nQuts5RaRqlt2HGd\nz7A+BrUbtj8Xe2xH3V/d9kvZX4O2ZdD9cr6+u8esv5/F1jZsP8133Pr3cf/6w7Zx2PjzPeaX81hZ\naIxB+3y++1qvr2HrLOfxk2RrVU0v1G45p4nWJLwv4ZKE0xP2TTgy4YsJFyW8I2GvphhelnBewsUJ\nb01IwtHANPC+hAsS9llGLZKkZVhOGNwTeFMV9wauAV4InAo8rYr7A2uA57dt31jFg9t3EvsAR1Vx\nOjALPKOKjVX8tH+AJMcnmU0yu3379mWUKkmaz3LC4Ioqzm6n3wscCVxWxdfaee8CjminH5Hw+YSL\ngEcC9x1lgKp6a1VNV9X0+vXrl1GqJGk+ywmD/rNYOwY1StgbeBNwdPuO4W3A3ssYV5I0ZmuWse6d\nEg6r4nPA79Gc8nluwt2q+Abw+8CnmXvivzphLXA0cHo771pg/2XUMJJNm+Y+kd+ypfl91llzy3vz\nFtsnwLZtcNxxN+1nw4bxfItmMbrjL2Wb5lunt70ABxwAJ5yw8Dq9ZRs2LL6W+cbv77+3/LOfhZe+\nFP7yL+GII5rbhx/eHKNhx6J7f+jdR3r3jWH7c8OGuWM+iu59YZTjspRj1x2nfzsG3f8XGnvLlp33\nyVJqG9a2v55TT73pt31642/bdtN1L7gANm6c/7h2x9+06aZtl/tY6dbTrXfQfu7WsXkzvPzlcMc7\nwo4dzXZ0++pff9D9fqUs59tE/5cmAA4BvkLz5H8Y8FqakDkPeH4VP0t4OfB04Erga8DlVcwk/A7w\n18BPgcMGfW7Qs5xvE0nSr6pRv020pDBYDYaBJC3ervhqqSRpD2EYSJIMA0mSYSBJwjCQJGEYSJIw\nDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk\nYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJFQiDhJmE\nE8fd7662efNo7WZmVmb8br8rMUavz82bYWpq/P3vSVbqGK+mmZm5Y9/bvv7fgyzmvrIn7bdRtmWc\n27vSj/9BUlXj7TDMANdV8dpx9js9PV2zs7Pj7HJeCYyya0Ztt5zxV2KMXp9Jc3sltmFPsVLHeDX1\njntP777Q/T1svVH3xZ6030bZlnFu7zgf/0m2VtX0Qu3G8s4g4eSEryV8FrhnO29jwrkJX0r4SMKt\n2vkPbuddkPCahIvHUYMkaemWHQYJhwDHABuBxwMPbhe9G3hxFQ8ALgK2tPPfCTy3io3ADfP3neOT\nzCaZ3b59+3JLlSQNMY53Bg8HPlLFT6q4BjgD2A9YV8Wn2zbvAo5IWAfsX8Xn2vnvn6/jqnprVU1X\n1fT69evHUKokaRC/TSRJGksYfAZ4csI+CfsDTwR+DPww4eFtm98HPl3FDuDahIe2848Zw/grYtOm\n0dpt2bJwm6Xo9rsSY/T63LQJNmwYf/97kpU6xqtpy5a5Y9/bvv7fgyzmvrIn7bdRtmWc27vSj/9B\nxvJtooSTgWOBq4BvAecD/w68GdgX+C/g2VX8sA2CtwG/BD4NTFfxmwuNsau/TSRJe4JRv020ZhyD\nVfEK4BUDFh06YN6X2w+VSXgJ4DO8JK2ysYTBIj0h4aR27MuB41ahBklSxy4PgypOA07b1eNKkobz\n20SSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEk\nCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwD\nSRKGgSQJw0CShGEgSWIMYZDw0YR14yhmpW3eDDMzc9PL0eunf97U1PDlo/SxnPEHtZmZGX1be7UP\n66vbz7DtH7ROb36vnsXq9TM1tfP+7fY7rKb+fkZdbznHZpS+FlP75s2Lu79OTc2179/3vb7mG6/b\ntrvPevt+0DGdmlrcfuyvb5j+dv1jD6t9kEGPh5kZWLeu+Rl0/+2uN6jf3v2yf71ef9393Wu39947\nb9ewbeq1We5z1ahSVUtfOaTpg18uq4gR+pmenq7Z2dnlDEPS/K5qppex6QPXX2z/y6lh1P57Rhln\nvj672zasbf+8/vH7+xhVt59BffXGXWifDKpn2HrLvX8s1Ff/2IvZ96OM12vf7b/fQuMNMmjfz9fn\nsO1azDEbtB3zHbdBdfRvV/d+PKz+QftulPGWuv/6t2nUfbSQJFuranqhdot+Z5AwlXBpwruBi4Eb\nEg5M+JuEF3TazSSc2E6/KOG8hC8lnDKkn4MXW4skaTyWepro7sCbqrgvcHk77zTgqZ02TwVOS3h0\n2/4hwEbgkIQj+vupurGfGyU5Pslsktnt27cvsVRJ0kKWGgaXV3Fud0YVXwR+PeH2CQ8EfljFFcCj\n258vAucD96IJgYH97NxnvbWqpqtqev369UssVZK0kDVLXO/HQ+Z/CDgauB3NOwWAAK+s4i3dhglT\n8/QjSdqFlhoGw5wGvA04ENjUzvsY8FcJ76viuoQ7ANePedyRbNo098n8pk3zNl3Qli2D55166vDl\no/SxnPGHtTnrrNH63LBh/r66/Qzb/kHr9Pb5Ure318+2bYPH6k0v1P+g+oatt5xjM0pf/WPPN95i\n76sbNsx9c6W//94xnO8bKt223Xa9+3b3cdRre+qpcNxxw/vq19umhfZzf7tBY48yXndZ//349a9v\npk84YXD7hY5N937Z7fOEE3be3739t9decOihc22HPUZ6277c56pRLfrbRO0r+jOruF97exswXcXV\n7e2LgKureERnnT8BntPevA54JnBDt5+FjOPbRJL0q2bUbxMt66ulu5JhIEmLt2JfLZUk7XkMA0mS\nYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJ\nwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNA\nkoRhIEnCMJAkMUIYJFw37kFXos9JNDOz2hUs3ai1787buKfY1cegO57Hf3xWe1+mquZvEK6rYu1Y\nB11Cn9PT0zU7OzvOMlZcAgvs3ok1au278zbuKXb1MeiO5/Efn5Xal0m2VtX0Qu1GPk2UsDnhzM7t\nNyYc105vSzgl4fyEixLu1c5fm/DOdt6XEn6ns/4rEi5MODfhtovaOknSWI3zM4Orq3gQ8I/Aie28\nvwB+VMX9q3gA8Kl2/n7AuVU8EPgM8IeDOkxyfJLZJLPbt28fY6mSpK5xhsGH299bgal2+lHAP/Qa\nVPHDdvLncOO7jG77nVTVW6tquqqm169fP8ZSJUldiwmDX/S137tv+c/a3zcAaxbo6/oqemfHRmkv\nSVpBiwmDy4H7JOyVsA44coR1PgG8oHcj4VaLrG+3tmXLalewdKPWvjtv455iVx+D7nge//FZ7X25\nqG8TJbwaeApwGXAdcEYVpyZsA6aruDphGnhtFZsT1tKcJjqE5h3AKVV8uK/Po4GjqpoPo4fZHb9N\nJEmrbdRvEy0YBpPCMJCkxRv7V0slSXsuw0CSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwk\nSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEY\nSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkgSkqla7\nhpEk2Q78GLh6tWsZ4kAmtzaY7PomuTaY7PomuTaY7PomuTYYX30bqmr9Qo12mzAASDJbVdOrXccg\nk1wbTHZ9k1wbTHZ9k1wbTHZ9k1wb7Pr6PE0kSTIMJEm7Xxi8dbULmMck1waTXd8k1waTXd8k1waT\nXd8k1wa7uL7d6jMDSdLK2N3eGUiSVoBhIEnaPcIgyWOTXJrkG0lesoLjvCPJVUku7sy7dZJPJPl6\n+/tWnWUntTVdmuQxnfmHJLmoXfY/k6Sdv1eS09r5n08ytcj6Dk7yH0m+kuTLSf5kUmpMsneSLyS5\nsK3tlEmprdPvzZN8McmZE1jbtrbfC5LMTmB965KcnuSrSS5Jctgk1Jfknu0+6/1ck+SESait0++f\nto+Ji5N8oH2sTEx9N6qqif4Bbg58E7gLcEvgQuA+KzTWEcCDgIs7814NvKSdfgnwqnb6Pm0tewF3\nbmu8ebvsC8ChQIB/Ax7Xzv8fwJvb6WOA0xZZ30HAg9rp/YGvtXWseo1tP2vb6VsAn2/7X/XaOjW+\nEHg/cOYEHtttwIF98yapvncBz2mnbwmsm6T6Os8VVwIbJqU24A7AZcA+7e0PAsdNSn071bqUlXbl\nD3AY8LHO7ZOAk1ZwvCl2DoNLgYPa6YOASwfVAXysrfUg4Kud+U8H3tJt006vofnrwiyj1v8N/Nak\n1QjsC5wPPHRSagPuCHwSeCRzYTARtbXrbOOmYTAR9QEH0DyhZRLr6/T3aODsSaqNJgyuAG7drntm\nW+dE1Nf92R1OE/V2Zs+323m7ym2r6nvt9JXAbReo6w7tdP/8ndapql8APwJus5Si2reCv0HzCnwi\namxPw1wAXAV8oqompjbg9cCfA7/szJuU2gAK+PckW5McP2H13RnYDryzPc329iT7TVB9PccAH2in\nJ6K2qvoO8FrgW8D3gB9V1ccnpb6u3SEMJkY10bvq38VNshb4X8AJVXVNd9lq1lhVN1TVRppX4Q9J\ncr9JqC3JUcBVVbV1WJsJOLaHt/vuccALkhzRXbjK9a2hOX36j1X1GzTXCNvps7vV3n9Jbgk8CfhQ\n/7LVrK39LOC3aQL19sB+SZ7ZbbPa+65ndwiD7wAHd27fsZ23q3w/yUEA7e+rFqjrO+10//yd1kmy\nhubt938vppgkt6AJgvdV1Ycnscaq2gH8B/DYCantN4EnJdkG/DPwyCTvnZDagBtfQVJVVwEfAR4y\nQfV9G/h2+04P4HSacJiU+qAJ0fOr6vvt7Ump7VHAZVW1vaquBz4MPGyC6rvR7hAG5wF3T3LnNv2P\nAc7YheOfARzbTh9Lc56+N/+Y9pP8OwN3B77QvvW7Jsmh7af9z+pbp9fX0cCn2lcFI2n7+yfgkqp6\n3STVmGR9knXt9D40n2V8dRJqq6qTquqOVTVFc//5VFU9cxJqA0iyX5L9e9M055QvnpT6qupK4Iok\n92xnHQl8ZVLqaz2duVNE/f2tZm3fAg5Nsm/b75HAJRNU35zFfsiwGj/A42m+OfNN4OQVHOcDNOf1\nrqd5NfQHNOfePgl8Hfh34Nad9ie3NV1K+8l+O3+a5sH8TeCNzP2l9940b2O/QfPNgLsssr7Dad5O\nfgm4oP15/CTUCDwA+GJb28XAy9r5q15bX52bmfsAeSJqo/mm3IXtz5d79/FJqa9dfyMw2x7ffwFu\nNSn1AfvRvBI+oDNvImpr1z+F5oXRxcB7aL4pNDH19X68HIUkabc4TSRJWmGGgSTJMJAkGQaSJAwD\nSRKGgfYgSf4uyQmd2x9L8vbO7b9N8sJl9D+T5MQhy45Pc0XPr6a5euvhnWUPT3PVyguS7JPkNe3t\n1yxy/Kkkv7fU+qX5GAbak5xN89edJLkZcCBw387yhwHnjNJR+5ecI2kvd/FcmktK3At4HvD+JLdr\nmzwDeGVVbayqnwLHAw+oqheNOkZrCjAMtCIMA+1JzqG5wiM0IXAxcG2SWyXZC7g3cH4ar0lzffmL\nkjwNIMnmJP+Z5Ayav7AlyclJvpbks8A9bzokAC8GXlRVVwNU1fk0l3x+QZLnAE8F/irJ+9q+1wJb\nkzwtye+2dVyY5DPtmDdv6zsvyZeSPLcd52+Ah7fvMP50nDtOGvnVjzTpquq7SX6R5E407wI+R3NF\nx8NoruR4UVX9PMnv0PxF7QNp3j2c13siprnmzv2q6rIkh9BcvmIjzWPlfGDQxe7uO2D+LHBsVf1F\ne8rozKo6HSDJddVclI4kFwGPqarv9C7nQfOX7z+qqge3IXZ2ko/TXBzuxKo6anl7Sropw0B7mnNo\nguBhwOtowuBhNGFwdtvmcOADVXUDzQXDPg08GLiG5jowl7XtHg58pKp+AtC+qh+3s4FTk3yQ5iJm\n0Fyb6AFJjm5vH0BzjZqfr8D4EuBpIu15ep8b3J/mNNG5NO8MRv284MdLGPMrwCF98w6huc7QvKrq\necBLaa46uTXJbWj+k9Uft58xbKyqO1dzDXxpxRgG2tOcAxwF/KCa/6/wA5p/0XgYc2Hwn8DT2nPz\n62n+3ekXBvT1GeDJ7TeA9geeOGTMVwOvap/ISbKR5l8bvmmhYpPctao+X1Uvo/kHMgfT/Oeq56e5\nXDlJ7tFezfRamn93Ko2dp4m0p7mI5nOA9/fNW9v7gJfm/wUcRnOV0AL+vKquTHKvbkdVdX6S09p2\nV9FcTv0mquqMJHcAzklSNE/az6y5/2Q1n9ckuTvNu4FPtmN9ieabQ+e3lyveDjy5nX9DkguBU6vq\n70boXxqJVy2VJHmaSJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkgT8fzQYLKkyLfBpAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x170e6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "textList.dispersion_plot([\"boat\", \"dog\", \"river\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default tokenization includes all surrounting punctuation charachters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81185"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can invoke RegexpTokenizer to eliminate punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68364"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will match any word characters until it reaches a non-word character, like a space\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(bk_3boat)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring lexical diversity: dividing unique words by overall words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09222146948327893"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(textList)) / len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_diversity_pct(text):\n",
    "    return (len(set(textList)) / len(textList))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.222146948327893"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_diversity_pct(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text normatliation with stemming and lemmatization\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "    am, are, is =>  be\n",
    "    dog, dogs, dog's, dogs' => dog\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    "\n",
    "    the girl's dogs are different breeds => the girl dog be differ breed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three',\n",
       " 'men',\n",
       " 'boat',\n",
       " 'say',\n",
       " 'nothing',\n",
       " 'dog',\n",
       " 'three',\n",
       " 'men',\n",
       " 'boat',\n",
       " 'jerome',\n",
       " 'jerome',\n",
       " 'chapter',\n",
       " 'three',\n",
       " 'invalids',\n",
       " 'sufferings',\n",
       " 'george',\n",
       " 'harris',\n",
       " 'victim',\n",
       " 'one',\n",
       " 'hundred']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting lists to strings to simplify displaying / visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l = (words[0:50])\n",
    "words_s = ', '.join(words_l)\n",
    "type (words_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (words_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three, men, boat, say, nothing, dog, three, men, boat, jerome, jerome, chapter, three, invalids, sufferings, george, harris, victim, one, hundred, seven, fatal, maladies, useful, prescriptions, cure, liver, complaint, children, agree, overworked, need, rest, week, rolling, deep, george, suggests, river, montmorency, lodges, objection, original, motion, carried, majority, three, one, four, us'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or using \"print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapter', 'three', 'invalid', 'suffer', 'georg', 'harri', 'victim', 'one', 'hundr', 'seven', 'fatal', 'maladi', 'use', 'prescript', 'cure', 'liver', 'complaint', 'children', 'agre', 'overwork', 'need', 'rest', 'week', 'roll', 'deep', 'georg', 'suggest', 'river', 'montmor', 'lodg', 'object', 'origin', 'motion', 'carri', 'major', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([porter.stem(t) for t in words[0:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapt', 'three', 'invalid', 'suff', 'georg', 'har', 'victim', 'on', 'hundr', 'sev', 'fat', 'malady', 'us', 'prescrib', 'cur', 'liv', 'complaint', 'childr', 'agr', 'overwork', 'nee', 'rest', 'week', 'rol', 'deep', 'georg', 'suggest', 'riv', 'montm', 'lodg', 'object', 'origin', 'mot', 'carry', 'maj', 'three', 'on', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in words[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n",
    "\n",
    "The WordNet lemmatizer only removes affixes if the resulting word is in its dictionary. The dictionary checking makes lemmatizers significantly slower than stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'u']\n"
     ]
    }
   ],
   "source": [
    "print([wnl.lemmatize(t) for t in words[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use help function to get explanations of endividual tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uc1 = \"The University of Chicago is a private research university in Chicago, Illinois\"\n",
    "uc2 = \"It is one of the world's leading and most influential institutions of higher learning, with top-ten positions in numerous rankings and measures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('private', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('university', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " (',', ','),\n",
       " ('Illinois', 'NNP')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc1)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list all possible tags and values\n",
    "#nltk.help.upenn_tagset('.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from URL\n",
    "#### BeautifulSoup to clean up meta-tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/University_of_Chicago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olors\n",
      "Maroon and White\n",
      "         \n",
      "\n",
      "\n",
      "Athletics\n",
      "NCAA Division III – UAA\n",
      "\n",
      "\n",
      "Nickname\n",
      "Maroons\n",
      "\n",
      "\n",
      "Affiliations\n",
      "AAU\n",
      "NAICU\n",
      "URA\n",
      "\n",
      "\n",
      "Mascot\n",
      "Phoenix\n",
      "\n",
      "\n",
      "Website\n",
      "www.uchicago.edu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The University of Chicago (U of C, Chicago, or UChicago) is a private research university in Chicago, Illinois. It holds top-ten positions in various national and international rankings.[6][7][8][9][10]\n",
      "The university is composed of the College, various graduate programs and interdisciplinary committees organized into five academic research divisions and seven professional schools. Beyond the arts and sciences, Chicago is also well known for its professional schools, which include the Pritzker School of Medicine, the Booth School of Business, the Law School, the School of Social Service Administration, the Harris School of Public Policy Studies, the Divinity School and the Graham School of Continuing Liberal and Professional Studies. The university currently enrolls 5,971 undergraduate students, and 16,016 students overall.[11]\n",
      "University of Chicago scholars have played a major role in the development of many academic disciplines, including sociology,[12] law,[13] economics,[14] literary criticism,[15] religion[16] and the behavioralism school of political science.[17] Chicago'\n"
     ]
    }
   ],
   "source": [
    "uc_wiki = (soup.get_text())\n",
    "#print (type(uc_wiki))\n",
    "print (uc_wiki[6740:8000]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even after BeautifulSoup we are left with a lot of garbade - mostly punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Humanities', 'Medalists', ',', '[', '26', ']', '13', 'billionaire', 'graduates', 'and', 'a', 'plethora', 'of', 'members', 'of', 'the', 'United', 'States', 'Congress', 'and', 'heads', 'of', 'state', 'of', 'countries', 'all', 'over', 'the', 'world', '.', '[', '27', ']', 'Contents', '1', 'History', '1.1', '1856–1890', '1.2', '1890s–1910s', '1.3', '1920s–1980s', '1.4', '1990s–2010s', '2', 'Campus', '2.1', 'Satellite', 'campuses', '3', 'Administration', 'and', 'finances', '4', 'Academics', '4.1', 'Undergraduate', 'college', '4.2', 'Graduate', 'schools', 'and', 'committees', '4.3', 'Professional', 'schools', '4.4', 'Associated', 'academic', 'institutions', '4.4.1', 'Controversies', 'surrounding', 'Bettelheim', '4.4.2', 'Library', 'system', '4.5', 'Research', '4.6', 'Arts', '4.7', 'Reputation', 'and', 'rankings', '5', 'Student', 'body', 'and', 'admissions', '6', 'Athletics', '7', 'Student', 'life', '7.1', 'Student', 'organizations', '7.1.1', 'Student']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_tokens = nltk.tokenize.word_tokenize(uc_wiki)\n",
    "uc_wiki_tokens_uncleaned = uc_wiki_tokens\n",
    "print (uc_wiki_tokens[2000:2100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chicago', 329),\n",
       " ('University', 310),\n",
       " ('The', 188),\n",
       " ('Retrieved', 134),\n",
       " ('university', 119),\n",
       " ('School', 75),\n",
       " ('College', 56),\n",
       " ('In', 55),\n",
       " ('students', 43),\n",
       " ('September', 39)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if len(word) > 1]\n",
    "\n",
    "# Remove punctuation\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if word.isalpha()]\n",
    "\n",
    "# Remove stopwords\n",
    "uc_wiki_tokens_no_stopwords = [word for word in uc_wiki_tokens if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(uc_wiki_tokens_no_stopwords)\n",
    "\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of our cleaned web scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'Chicago', 'Wikipedia', 'function', 'wgCanonicalNamespace', 'wgCanonicalSpecialPageName', 'false', 'wgNamespaceNumber', 'wgPageName', 'wgTitle', 'University', 'Chicago', 'wgCurRevisionId', 'wgRevisionId', 'wgArticleId', 'wgIsArticle', 'true', 'wgIsRedirect', 'false', 'wgAction', 'view', 'wgUserName', 'null', 'wgUserGroups', 'wgCategories', 'maint', 'BOT', 'status', 'unknown', 'errors', 'external', 'links', 'All', 'articles', 'dead', 'external', 'links', 'Articles', 'dead', 'external', 'links', 'December', 'Articles', 'permanently', 'dead', 'external', 'links', 'Use', 'mdy', 'dates', 'April', 'Good', 'articles', 'Articles', 'containing', 'text', 'Pages', 'using', 'deprecated', 'image', 'syntax', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'May', 'All', 'articles', 'containing', 'potentially', 'dated', 'statements', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'All', 'articles', 'unsourced', 'statements', 'Articles', 'unsourced', 'statements', 'June', 'Official', 'website', 'different', 'Wikidata', 'Wikipedia', 'Coordinates', 'Wikidata', 'Wikipedia', 'articles', 'VIAF', 'identifiers', 'Wikipedia', 'articles', 'LCCN']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords = nltk.Text(uc_wiki_tokens_no_stopwords)\n",
    "print (uc_wiki_text_no_stopwords[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation and noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', 'Wikipedia', 'function', 'wgCanonicalNamespace', 'wgCanonicalSpecialPageName', 'false', 'wgNamespaceNumber', 'wgPageName', 'wgTitle', 'University', 'of', 'Chicago', 'wgCurRevisionId', 'wgRevisionId', 'wgArticleId', 'wgIsArticle', 'true', 'wgIsRedirect', 'false', 'wgAction', 'view', 'wgUserName', 'null', 'wgUserGroups', 'wgCategories', 'maint', 'BOT', 'status', 'unknown', 'errors', 'external', 'links', 'All', 'articles', 'with', 'dead', 'external', 'links', 'Articles', 'with', 'dead', 'external', 'links', 'from', 'December', 'Articles', 'with', 'permanently', 'dead', 'external', 'links', 'Use', 'mdy', 'dates', 'from', 'April', 'Good', 'articles', 'Articles', 'containing', 'text', 'Pages', 'using', 'deprecated', 'image', 'syntax', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'from', 'May', 'All', 'articles', 'containing', 'potentially', 'dated', 'statements', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'from', 'All', 'articles', 'with', 'unsourced', 'statements', 'Articles', 'with', 'unsourced', 'statements', 'from', 'June', 'Official', 'website']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned = nltk.Text(uc_wiki_tokens)\n",
    "print (uc_wiki_text_cleaned[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', '-', 'Wikipedia', 'document.documentElement.className', '=', 'document.documentElement.className.replace', '(', '/', '(', '^|\\\\s', ')', 'client-nojs', '(', '\\\\s|', '$', ')', '/', ',', '``', '$', '1client-js', '$', '2', \"''\", ')', ';', '(', 'window.RLQ=window.RLQ||', '[', ']', ')', '.push', '(', 'function', '(', ')', '{', 'mw.config.set', '(', '{', '``', 'wgCanonicalNamespace', \"''\", ':', \"''\", \"''\", ',', \"''\", 'wgCanonicalSpecialPageName', \"''\", ':', 'false', ',', \"''\", 'wgNamespaceNumber', \"''\", ':0', ',', \"''\", 'wgPageName', \"''\", ':', \"''\", 'University_of_Chicago', \"''\", ',', \"''\", 'wgTitle', \"''\", ':', \"''\", 'University', 'of', 'Chicago', \"''\", ',', \"''\", 'wgCurRevisionId', \"''\", ':818688066', ',', \"''\", 'wgRevisionId', \"''\", ':818688066', ',', \"''\", 'wgArticleId', \"''\", ':32127', ',', \"''\", 'wgIsArticle', \"''\", ':', 'true', ',', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw = nltk.Text(uc_wiki_tokens_uncleaned)\n",
    "print (uc_wiki_text_raw[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying simlarity function - which option produces best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memoir reputation spurs site notify buildings cornell minnesota purdue\n",
      "in stetson isbn single maroon rutgers campus history retrieved iowa\n",
      "pittsburgh\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation andl noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college school president first history department office board world\n",
      "association faculty chicago author campus buildings study law founder\n",
      "developer site\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college school president department office board world association\n",
      "faculty chicago author campus buildings first history study law\n",
      "founder to developer\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging our web page with POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order for the tagger to be effective, it has to tag each word based on the word itself, as well as its context within a sentence. \n",
    "Depending on your corpus, certain taggers perform better the others.  Like with SPSS TA dictionaries, you can start with pre-trained POS Tagger and then try multiple different options to see which one will perform best for you.\n",
    "You can also customize and train your own taggers to match your particular corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uc_wiki_tagged = nltk.pos_tag(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('function', 'NN'),\n",
       " ('wgCanonicalNamespace', 'NN'),\n",
       " ('wgCanonicalSpecialPageName', 'NN'),\n",
       " ('false', 'JJ'),\n",
       " ('wgNamespaceNumber', 'NN'),\n",
       " ('wgPageName', 'NN')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_wiki_tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring alternative text analysis packages: TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('document.documentElement.className', 'NN'),\n",
       " ('=', 'NNP'),\n",
       " ('document.documentElement.className.replace', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('^|\\\\s', 'NNP'),\n",
       " ('client-nojs', 'NN')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To process  cleaned-up version from NLTK we will have to convert text from nltk.text.Text to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "words_list = (uc_wiki_text_cleaned[0:])\n",
    "words_string = ', '.join(words_l)\n",
    "print(type(words_list))\n",
    "print(type(words_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(words_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('three', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('boat', 'NN'),\n",
       " ('say', 'VBP'),\n",
       " ('nothing', 'NN'),\n",
       " ('dog', 'NN'),\n",
       " ('three', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('boat', 'NN'),\n",
       " ('jerome', 'NN')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be careful with embedded functions to pluralize and singularize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = TextBlob(words_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three', 'invalids', 'sufferings']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'invalid', 'suffering'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[12:15].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['men', 'boat']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['threes', 'mens', 'boats'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:3].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:20].lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'committees', '4.3', 'Professional', 'schools', '4.4', 'Associated', 'academic', 'institutions', '4.4.1', 'Controversies', 'surrounding', 'Bettelheim', '4.4.2', 'Library', 'system', '4.5', 'Research', '4.6', 'Arts']\n"
     ]
    }
   ],
   "source": [
    "b_words = blob.words\n",
    "print (b_words[1020:1040])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"The university is also home to the University of Chicago Press, the largest university press in the United States.\"), Sentence(\"[19] With an estimated completion date of 2020, the Barack Obama Presidential Center will be housed at the university and include both the Obama presidential library and offices of the Obama Foundation.\"), Sentence(\"[20]\n",
      "The University of Chicago has many prominent alumni, faculty members and researchers.\"), Sentence(\"92 Nobel laureates[21] have been affiliated with the university as professors, students, faculty, or staff, making it the fifth most of any institution in the world.\"), Sentence(\"Similarly, 34 faculty members and 17 alumni have been awarded the MacArthur \"Genius Grant\".\")]\n"
     ]
    }
   ],
   "source": [
    "b_sentences = blob.sentences\n",
    "print (b_sentences[10:15])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
