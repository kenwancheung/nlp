{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4-Kenwan\n",
    "\n",
    "### GOAL: Create classification model, predicting the outcome of food safety inspection based on the inspectors’ comments\n",
    "\n",
    "### Details:\n",
    "\n",
    "1. Leverage the results of your homework from Week-1 and Week-2 to extract free-form text comments from inspectors/ Discard the text from “Health Code” – only keep inspectors’ comments.\n",
    "2. Build classification model, predicting the outcome of inspection – your target variable is “Results”\n",
    "3. Explain why you selected a particular text pre-processing technique\n",
    "4. Visualize results of at least two text classifiers and select the most robust one. You can choose to build a binary classifier (limiting your data to Pass / Fail) or multinomial classifier with all available values in Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Boog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import combinations\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_compare_files(file1,file2,n):\n",
    "    # Takes two files\n",
    "    # hashes their n-grams into twos lists\n",
    "    # calculates the intersection and union\n",
    "    # of the two lists, and returns\n",
    "    # Jacard similarity value\n",
    " \n",
    "    stop = stopwords.words('english')\n",
    "    f1 = open(file1)\n",
    "    raw = f1.read()\n",
    "    f1.close()\n",
    "    f1_grams = nltk.ngrams(raw.split(),n)\n",
    "    \n",
    "    array_1 = []\n",
    "    \n",
    "    for gram in f1_grams:\n",
    "        array_1.append(hash(gram))\n",
    "    f2 = open(file2)\n",
    "    raw = f2.read()\n",
    "    f2.close()\n",
    "    f2_grams = nltk.ngrams(raw.split(),n)\n",
    "    \n",
    "    array_2 = []\n",
    "    \n",
    "    for gram in f2_grams:\n",
    "        array_2.append(hash(gram))\n",
    "        \n",
    "    intersection = len(list(set(array_1).intersection(array_2)))    \n",
    "    union = len(set(array_1)) + len(set(array_2)) - intersection\n",
    "    jacard_similarity = intersection / union\n",
    "    return jacard_similarity\n",
    "\n",
    "\n",
    "def pairs_of_files(directory):\n",
    "    # returns combination of two files given\n",
    "    # all files in a directory\n",
    "    \n",
    "    dir = os.listdir(directory)\n",
    "    combo = combinations(dir, 2)\n",
    "    return combo\n",
    "\n",
    "def compare_files(directory,ngram_size,threshold):\n",
    "    # compares all pairs of files in a directory\n",
    "    # for similarity.\n",
    "    # RETURNS: Dictionary, with key as\n",
    "    # comma-separated string of two files\n",
    "    # and value of similarity index as decimal\n",
    "    # where similarity index is above threshold\n",
    "    # value.\n",
    "    \n",
    "    compare_dictionary = {}\n",
    "    \n",
    "    ngram = ngram_size\n",
    "    combo = pairs_of_files(directory)\n",
    "    \n",
    "    for i in combo:\n",
    "        \n",
    "        sim = ngram_compare_files(directory+str(i[0]),directory+str(i[1]),ngram)\n",
    "        if sim > threshold:\n",
    "            \n",
    "            key = str(i[0]) + \",\" + str(i[1])\n",
    "            value = sim\n",
    "            compare_dictionary[key]=value\n",
    "            \n",
    "    return compare_dictionary            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_b = '../wk3/Assignment 3 Books/'\n",
    "dir_a = '../wk3/Assignment 3 Articles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "yall = []\n",
    "\n",
    "for n in range(2,20):\n",
    "        \n",
    "    books_comparison = compare_files(dir_b,ngram_size=n,threshold=-1)\n",
    "    a = np.zeros(len(books_comparison))\n",
    "    counter = 0\n",
    "    for key, value in books_comparison.items():\n",
    "        a[counter] = value\n",
    "        counter +=1\n",
    "    #print str(n) + \":\" + str(a.mean())\n",
    "    x.append(n)\n",
    "    yall.append(a*100)\n",
    "    y.append(a.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We've run the function to load the data and run ngrams\n",
    "\n",
    "The function returns the jaccard similarity (intersection / (total - intersection)) of the lists. We can plot them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y, linestyle = '-')\n",
    "#plt.plot(x,yall, linestyle = '--')\n",
    "plt.xlabel('n in n-grams')\n",
    "plt.ylabel('Similarity (pct)')\n",
    "plt.title('Similarity Across All Books per N n-gram')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
