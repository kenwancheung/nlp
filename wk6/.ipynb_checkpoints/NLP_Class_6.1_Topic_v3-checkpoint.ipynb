{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced text mining with Python - Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4 |Anaconda custom (64-bit)| (default, Aug 14 2017, 13:41:13) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'C://Users//Nick//Documents//Teaching//Data Projects//Text//Tweets//'\n",
    "#file = 'jeep.txt'\n",
    "file = 'jeep_new.txt'\n",
    "path = directory + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(path,sep='\\t', names = ['id', 'lang', 'created_at', 'screen_name', \\\n",
    "                                                       'name', 'location', 'retweet_count', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               68921\n",
       "lang             68921\n",
       "created_at       68921\n",
       "screen_name      68921\n",
       "name             68921\n",
       "location         46879\n",
       "retweet_count    68921\n",
       "text             68921\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.222399e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Sun Oct 22 23:15:03 +0000 2017</td>\n",
       "      <td>alyssa_rose4</td>\n",
       "      <td>Princess Alyssa‚ôõ</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@Rachel_31297 where‚Äôs the Jeep Wrangler option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.222399e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Sun Oct 22 23:15:09 +0000 2017</td>\n",
       "      <td>negocialoya_us</td>\n",
       "      <td>NegocialoYa USA</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Check this out: 2016 JEEP PATRIOT LATITUDE 4X4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>tl</td>\n",
       "      <td>Sun Oct 22 23:15:14 +0000 2017</td>\n",
       "      <td>Jasmne_abr</td>\n",
       "      <td>Jas</td>\n",
       "      <td>blueberry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kadugay sa jeep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Sun Oct 22 23:15:15 +0000 2017</td>\n",
       "      <td>JFCO38</td>\n",
       "      <td>JUAN FCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @Jeep: The Grand Cherokee Trackhawk is offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>tl</td>\n",
       "      <td>Sun Oct 22 23:15:15 +0000 2017</td>\n",
       "      <td>MaestreRaymond</td>\n",
       "      <td>Jin Rae Min</td>\n",
       "      <td>Northern Mindanao</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kadugay mularga sa jeep nga kadali koüò¨üò≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>tl</td>\n",
       "      <td>Sun Oct 22 23:15:21 +0000 2017</td>\n",
       "      <td>troyxaquino</td>\n",
       "      <td>Troy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bang luluwag ng mga jeep hahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Sun Oct 22 23:15:27 +0000 2017</td>\n",
       "      <td>LifeForTrucker</td>\n",
       "      <td>TruckerForLife‚Ñ¢</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @Jeep: Power stance. https://t.co/kl0oC8Xvof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>Sun Oct 22 23:15:30 +0000 2017</td>\n",
       "      <td>rpx53</td>\n",
       "      <td>Rod O|||||||O</td>\n",
       "      <td>Where the blacktop ends</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@THEJeepMafia @Jeep Thanks, 28¬∞ but Chaos and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.222400e+17</td>\n",
       "      <td>tl</td>\n",
       "      <td>Sun Oct 22 23:15:34 +0000 2017</td>\n",
       "      <td>ronneldash</td>\n",
       "      <td>üè≥Ô∏è‚ÄçüåàROXüè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>St. Paul</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tangina mula 6:00 nasa sakayan ako tas 7:30 na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.222401e+17</td>\n",
       "      <td>tl</td>\n",
       "      <td>Sun Oct 22 23:15:49 +0000 2017</td>\n",
       "      <td>FayeUsi</td>\n",
       "      <td>aria</td>\n",
       "      <td>Las Pinas City, National Capit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@Dncyngs ikaw yung nakakasabay ko lagi sa jeep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id lang                      created_at     screen_name  \\\n",
       "0  9.222399e+17   en  Sun Oct 22 23:15:03 +0000 2017    alyssa_rose4   \n",
       "1  9.222399e+17   en  Sun Oct 22 23:15:09 +0000 2017  negocialoya_us   \n",
       "2  9.222400e+17   tl  Sun Oct 22 23:15:14 +0000 2017      Jasmne_abr   \n",
       "3  9.222400e+17   en  Sun Oct 22 23:15:15 +0000 2017          JFCO38   \n",
       "4  9.222400e+17   tl  Sun Oct 22 23:15:15 +0000 2017  MaestreRaymond   \n",
       "5  9.222400e+17   tl  Sun Oct 22 23:15:21 +0000 2017     troyxaquino   \n",
       "6  9.222400e+17   en  Sun Oct 22 23:15:27 +0000 2017  LifeForTrucker   \n",
       "7  9.222400e+17   en  Sun Oct 22 23:15:30 +0000 2017           rpx53   \n",
       "8  9.222400e+17   tl  Sun Oct 22 23:15:34 +0000 2017      ronneldash   \n",
       "9  9.222401e+17   tl  Sun Oct 22 23:15:49 +0000 2017         FayeUsi   \n",
       "\n",
       "               name                        location  retweet_count  \\\n",
       "0  Princess Alyssa‚ôõ                     Chicago, IL            0.0   \n",
       "1   NegocialoYa USA                  Estados Unidos            0.0   \n",
       "2               Jas                       blueberry            0.0   \n",
       "3          JUAN FCO                             NaN            0.0   \n",
       "4       Jin Rae Min               Northern Mindanao            0.0   \n",
       "5              Troy                             NaN            0.0   \n",
       "6   TruckerForLife‚Ñ¢                   United States            0.0   \n",
       "7     Rod O|||||||O         Where the blacktop ends            0.0   \n",
       "8       üè≥Ô∏è‚ÄçüåàROXüè≥Ô∏è‚Äçüåà                        St. Paul            0.0   \n",
       "9              aria  Las Pinas City, National Capit            0.0   \n",
       "\n",
       "                                                text  \n",
       "0     @Rachel_31297 where‚Äôs the Jeep Wrangler option  \n",
       "1  Check this out: 2016 JEEP PATRIOT LATITUDE 4X4...  \n",
       "2                                    Kadugay sa jeep  \n",
       "3  RT @Jeep: The Grand Cherokee Trackhawk is offi...  \n",
       "4            Kadugay mularga sa jeep nga kadali koüò¨üò≠  \n",
       "5                    Bang luluwag ng mga jeep hahaha  \n",
       "6    RT @Jeep: Power stance. https://t.co/kl0oC8Xvof  \n",
       "7  @THEJeepMafia @Jeep Thanks, 28¬∞ but Chaos and ...  \n",
       "8  tangina mula 6:00 nasa sakayan ako tas 7:30 na...  \n",
       "9  @Dncyngs ikaw yung nakakasabay ko lagi sa jeep...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter non-English tweets\n",
    "tweets_eng = tweets[tweets['lang']=='en'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove special characters to avoid problems with analysis\n",
    "tweets_eng['text_clean'] = tweets_eng['text'].map(lambda x: re.sub('[^a-zA-Z0-9 @ . , : - _]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Rachel_31297 where‚Äôs the Jeep Wrangler option</td>\n",
       "      <td>@Rachel_31297 wheres the Jeep Wrangler option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check this out: 2016 JEEP PATRIOT LATITUDE 4X4 - $8500 (MIAMI-DADE) 8500.00 USD https://t.co/akP...</td>\n",
       "      <td>Check this out: 2016 JEEP PATRIOT LATITUDE 4X4  8500 MIAMIDADE 8500.00 USD https:t.coakPkANPpEn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Jeep: The Grand Cherokee Trackhawk is officially in production. Keep your eyes peeled for on...</td>\n",
       "      <td>RT @Jeep: The Grand Cherokee Trackhawk is officially in production. Keep your eyes peeled for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @Jeep: Power stance. https://t.co/kl0oC8Xvof</td>\n",
       "      <td>RT @Jeep: Power stance. https:t.cokl0oC8Xvof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@THEJeepMafia @Jeep Thanks, 28¬∞ but Chaos and Bear were awesome feet warmers! üêæüêæ https://t.co/nN...</td>\n",
       "      <td>@THEJeepMafia @Jeep Thanks, 28 but Chaos and Bear were awesome feet warmers  https:t.conNIoaRVXlW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                                       @Rachel_31297 where‚Äôs the Jeep Wrangler option   \n",
       "1  Check this out: 2016 JEEP PATRIOT LATITUDE 4X4 - $8500 (MIAMI-DADE) 8500.00 USD https://t.co/akP...   \n",
       "2  RT @Jeep: The Grand Cherokee Trackhawk is officially in production. Keep your eyes peeled for on...   \n",
       "3                                                      RT @Jeep: Power stance. https://t.co/kl0oC8Xvof   \n",
       "4  @THEJeepMafia @Jeep Thanks, 28¬∞ but Chaos and Bear were awesome feet warmers! üêæüêæ https://t.co/nN...   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0                                                        @Rachel_31297 wheres the Jeep Wrangler option  \n",
       "1  Check this out: 2016 JEEP PATRIOT LATITUDE 4X4  8500 MIAMIDADE 8500.00 USD https:t.coakPkANPpEn ...  \n",
       "2  RT @Jeep: The Grand Cherokee Trackhawk is officially in production. Keep your eyes peeled for on...  \n",
       "3                                                         RT @Jeep: Power stance. https:t.cokl0oC8Xvof  \n",
       "4    @THEJeepMafia @Jeep Thanks, 28 but Chaos and Bear were awesome feet warmers  https:t.conNIoaRVXlW  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "tweets_eng[['text', 'text_clean']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "#### Topics can be defined as ‚Äúa repeating pattern of co-occurring terms in a corpus‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (term frequency‚Äìinverse document frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using TextBlob functionality to create TF-IDF function for our select Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "# tf(word, blob) computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "# normalized by dividing by the total number of words in blob. We use TextBlob for breaking up the text into words \n",
    "# and getting the word counts.\n",
    "\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "# n_containing(word, bloblist) returns the number of documents containing word. \n",
    "# A generator expression is passed to the sum() function.\n",
    "\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "# idf(word, bloblist) computes \"inverse document frequency\" which measures how common a word is \n",
    "# among all documents in bloblist. The more common a word is, the lower its idf. \n",
    "# We take the ratio of the total number of documents to the number of documents containing word, \n",
    "# then take the log of that. Add 1 to the divisor to prevent division by zero\n",
    "\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)\n",
    "# tfidf(word, blob, bloblist) computes the TF-IDF score. It is simply the product of tf and idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40704"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloblist = []\n",
    "del bloblist[:]\n",
    "\n",
    "for i  in range(0,len(tweets_eng)):\n",
    "    bloblist.append(TextBlob(tweets_eng['text_clean'].iloc[i]))\n",
    "    \n",
    "len(bloblist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in tweet 1\n",
      "\tWord: Rachel_31297, TF-IDF: 1.65349\n",
      "\tWord: wheres, TF-IDF: 1.50077\n",
      "\tWord: option, TF-IDF: 1.226\n",
      "\tWord: Wrangler, TF-IDF: 0.38572\n",
      "\tWord: the, TF-IDF: 0.28659\n",
      "Top words in tweet 2\n",
      "\tWord: t.coL2WaZBsUTf, TF-IDF: 0.58358\n",
      "\tWord: t.coakPkANPpEn, TF-IDF: 0.58358\n",
      "\tWord: 8500.00, TF-IDF: 0.55973\n",
      "\tWord: MIAMIDADE, TF-IDF: 0.55973\n",
      "\tWord: 8500, TF-IDF: 0.51896\n",
      "Top words in tweet 3\n",
      "\tWord: t.cobbiPfPXXax, TF-IDF: 0.34509\n",
      "\tWord: peeled, TF-IDF: 0.34191\n",
      "\tWord: wild, TF-IDF: 0.31915\n",
      "\tWord: Keep, TF-IDF: 0.31915\n",
      "\tWord: officially, TF-IDF: 0.31637\n",
      "Top words in tweet 4\n",
      "\tWord: t.cokl0oC8Xvof, TF-IDF: 0.89363\n",
      "\tWord: stance, TF-IDF: 0.89104\n",
      "\tWord: Power, TF-IDF: 0.85214\n",
      "\tWord: RT, TF-IDF: 0.18822\n",
      "\tWord: Jeep, TF-IDF: 0.06069\n",
      "Top words in tweet 5\n",
      "\tWord: t.conNIoaRVXlW, TF-IDF: 0.70864\n",
      "\tWord: warmers, TF-IDF: 0.65913\n",
      "\tWord: Chaos, TF-IDF: 0.63017\n",
      "\tWord: Bear, TF-IDF: 0.60962\n",
      "\tWord: feet, TF-IDF: 0.56011\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(bloblist):\n",
    "# Print top 5 values\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"Top words in tweet {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:5]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LDA (latent dirichlet allocation)\n",
    "#### LDA is a matrix factorization technique, which assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = \"BMW upbeat sustained sales growth\"\n",
    "doc2 = \"Ad wars When BMW Audi Mercedes Benz Jaguar prove prowess throughadvertisements\"\n",
    "doc3 = \"BMW Protonic Frozen Yellow Edition Looks So Cool\"\n",
    "doc4 = \"Judge Shuts Door On SoftClose Defect Suit Against BMW Law\"\n",
    "doc5 = \"Just Listed BMW Alpina B Turbo Automobile Magazine\"\n",
    "doc6 = \"How take part BMW Ultimate Driving Experience\"\n",
    "doc7 = \"Long Beach BMW Motorcycles Becomes First BMW Dealer Offer Virtual Reality Experience Virtual Reality Reporter\"\n",
    "doc8 = \"NYC Auto Show BMW M Performance Video Overview\"\n",
    "doc9 = \"BMW F X Spy video shows SUV stress test\"\n",
    "doc10 = \"Driver taken hospital BMW smashes tree Stourbridge Express Star\"\n",
    "\n",
    "# compile documents\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5, doc6, doc7, doc8, doc9, doc10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 880 ms\n",
      "(0, '0.075*\"bmw\" + 0.052*\"reality\" + 0.052*\"virtual\"')\n",
      "\n",
      "(1, '0.062*\"bmw\" + 0.036*\"show\" + 0.036*\"video\"')\n",
      "\n",
      "(2, '0.092*\"bmw\" + 0.019*\"jaguar\" + 0.019*\"war\"')\n"
     ]
    }
   ],
   "source": [
    "# Running and Trainign LDA model on the document term matrix.\n",
    "%time ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50) #3 topics\n",
    "print(*ldamodel.print_topics(num_topics=3, num_words=3), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 820 ms\n",
      "(0, '0.083*\"bmw\" + 0.057*\"virtual\" + 0.057*\"reality\" + 0.031*\"motorcycle\" + 0.031*\"long\"')\n",
      "\n",
      "(1, '0.083*\"bmw\" + 0.057*\"video\" + 0.057*\"show\" + 0.031*\"x\" + 0.031*\"spy\"')\n",
      "\n",
      "(2, '0.095*\"bmw\" + 0.036*\"law\" + 0.036*\"door\" + 0.036*\"judge\" + 0.036*\"softclose\"')\n",
      "\n",
      "(3, '0.061*\"experience\" + 0.061*\"ultimate\" + 0.061*\"part\" + 0.061*\"take\" + 0.061*\"driving\"')\n",
      "\n",
      "(4, '0.058*\"cool\" + 0.058*\"protonic\" + 0.058*\"yellow\" + 0.058*\"look\" + 0.058*\"edition\"')\n"
     ]
    }
   ],
   "source": [
    "%time ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=50) #5 topics\n",
    "print(*ldamodel.print_topics(num_topics=5, num_words=5), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Applying LDA to tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Rachel_31297 wheres the Jeep Wrangler option',\n",
       " 'Check this out: 2016 JEEP PATRIOT LATITUDE 4X4  8500 MIAMIDADE 8500.00 USD https:t.coakPkANPpEn ads https:t.coL2WaZBsUTf',\n",
       " 'RT @Jeep: The Grand Cherokee Trackhawk is officially in production. Keep your eyes peeled for one in the wild. https:t.cobbiPfPXXax',\n",
       " 'RT @Jeep: Power stance. https:t.cokl0oC8Xvof',\n",
       " '@THEJeepMafia @Jeep Thanks, 28 but Chaos and Bear were awesome feet warmers  https:t.conNIoaRVXlW']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = tweets_eng['text_clean'].tolist()\n",
    "tweets_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "tweet_clean = [clean(doc).split() for doc in tweets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rachel31297', 'wheres', 'jeep', 'wrangler', 'option']\n",
      "\n",
      "['check', 'out', '2016', 'jeep', 'patriot', 'latitude', '4x4', '8500', 'miamidade', '850000', 'usd', 'httpstcoakpkanppen', 'ad', 'httpstcol2wazbsutf']\n",
      "\n",
      "['rt', 'jeep', 'grand', 'cherokee', 'trackhawk', 'officially', 'production', 'keep', 'eye', 'peeled', 'one', 'wild', 'httpstcobbipfpxxax']\n"
     ]
    }
   ],
   "source": [
    "print(*tweet_clean[:3], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 750 ms\n"
     ]
    }
   ],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "\n",
    "dictionary = corpora.Dictionary(tweet_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "\n",
    "%time doc_term_matrix = [dictionary.doc2bow(doc) for doc in tweet_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28min 20s\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "%time ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.082*\"jeep\" + 0.025*\"rt\" + 0.014*\"amp\"')\n",
      "\n",
      "(1, '0.103*\"giveaway\" + 0.059*\"girl\" + 0.058*\"win\"')\n",
      "\n",
      "(2, '0.093*\"jeep\" + 0.035*\"rt\" + 0.014*\"credit\"')\n",
      "\n",
      "(3, '0.067*\"jeep\" + 0.037*\"wrangler\" + 0.029*\"via\"')\n",
      "\n",
      "(4, '0.129*\"jeep\" + 0.093*\"rt\" + 0.020*\"luxbucketlist\"')\n",
      "\n",
      "(5, '0.090*\"jeep\" + 0.078*\"rt\" + 0.021*\"jeepporn\"')\n",
      "\n",
      "(6, '0.118*\"jeep\" + 0.050*\"wrangler\" + 0.036*\"cherokee\"')\n",
      "\n",
      "(7, '0.069*\"jeep\" + 0.019*\"new\" + 0.013*\"rt\"')\n",
      "\n",
      "(8, '0.071*\"jeep\" + 0.024*\"rt\" + 0.016*\"dodge\"')\n",
      "\n",
      "(9, '0.086*\"jeep\" + 0.035*\"used\" + 0.032*\"photo\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=10, num_words=3), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.082*\"jeep\" + 0.025*\"rt\" + 0.014*\"amp\" + 0.014*\"like\" + 0.010*\"dont\"')\n",
      "\n",
      "(1, '0.103*\"giveaway\" + 0.059*\"girl\" + 0.058*\"win\" + 0.058*\"jeep\" + 0.053*\"small\"')\n",
      "\n",
      "(2, '0.093*\"jeep\" + 0.035*\"rt\" + 0.014*\"credit\" + 0.013*\"photo\" + 0.013*\"got\"')\n",
      "\n",
      "(3, '0.067*\"jeep\" + 0.037*\"wrangler\" + 0.029*\"via\" + 0.021*\"renegade\" + 0.020*\"check\"')\n",
      "\n",
      "(4, '0.129*\"jeep\" + 0.093*\"rt\" + 0.020*\"luxbucketlist\" + 0.018*\"jeeplife\" + 0.018*\"need\"')\n",
      "\n",
      "(5, '0.090*\"jeep\" + 0.078*\"rt\" + 0.021*\"jeepporn\" + 0.016*\"compass\" + 0.014*\"make\"')\n",
      "\n",
      "(6, '0.118*\"jeep\" + 0.050*\"wrangler\" + 0.036*\"cherokee\" + 0.022*\"grand\" + 0.019*\"sport\"')\n",
      "\n",
      "(7, '0.069*\"jeep\" + 0.019*\"new\" + 0.013*\"rt\" + 0.009*\"car\" + 0.008*\"2018\"')\n",
      "\n",
      "(8, '0.071*\"jeep\" + 0.024*\"rt\" + 0.016*\"dodge\" + 0.015*\"chrysler\" + 0.010*\"top\"')\n",
      "\n",
      "(9, '0.086*\"jeep\" + 0.035*\"used\" + 0.032*\"photo\" + 0.029*\"spotted\" + 0.028*\"stick\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=10, num_words=5), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.082*\"jeep\" + 0.025*\"rt\" + 0.014*\"amp\" + 0.014*\"like\" + 0.010*\"dont\" + 0.009*\"get\" + 0.009*\"im\"')\n",
      "\n",
      "(1, '0.103*\"giveaway\" + 0.059*\"girl\" + 0.058*\"win\" + 0.058*\"jeep\" + 0.053*\"small\" + 0.053*\"body\" + 0.053*\"sun\"')\n",
      "\n",
      "(2, '0.093*\"jeep\" + 0.035*\"rt\" + 0.014*\"credit\" + 0.013*\"photo\" + 0.013*\"got\" + 0.013*\"day\" + 0.012*\"want\"')\n",
      "\n",
      "(3, '0.067*\"jeep\" + 0.037*\"wrangler\" + 0.029*\"via\" + 0.021*\"renegade\" + 0.020*\"check\" + 0.019*\"ebay\" + 0.016*\"decal\"')\n",
      "\n",
      "(4, '0.129*\"jeep\" + 0.093*\"rt\" + 0.020*\"luxbucketlist\" + 0.018*\"jeeplife\" + 0.018*\"need\" + 0.017*\"life\" + 0.016*\"matte\"')\n",
      "\n",
      "(5, '0.090*\"jeep\" + 0.078*\"rt\" + 0.021*\"jeepporn\" + 0.016*\"compass\" + 0.014*\"make\" + 0.012*\"looking\" + 0.009*\"mean\"')\n",
      "\n",
      "(6, '0.118*\"jeep\" + 0.050*\"wrangler\" + 0.036*\"cherokee\" + 0.022*\"grand\" + 0.019*\"sport\" + 0.015*\"ebay\" + 0.013*\"unlimited\"')\n",
      "\n",
      "(7, '0.069*\"jeep\" + 0.019*\"new\" + 0.013*\"rt\" + 0.009*\"car\" + 0.008*\"2018\" + 0.008*\"man\" + 0.008*\"cherokee\"')\n",
      "\n",
      "(8, '0.071*\"jeep\" + 0.024*\"rt\" + 0.016*\"dodge\" + 0.015*\"chrysler\" + 0.010*\"top\" + 0.008*\"ram\" + 0.008*\"know\"')\n",
      "\n",
      "(9, '0.086*\"jeep\" + 0.035*\"used\" + 0.032*\"photo\" + 0.029*\"spotted\" + 0.028*\"stick\" + 0.027*\"bamboo\" + 0.027*\"nigeria\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=10, num_words=7), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.082*\"jeep\" + 0.025*\"rt\" + 0.014*\"amp\" + 0.014*\"like\" + 0.010*\"dont\" + 0.009*\"get\" + 0.009*\"im\" + 0.008*\"november\" + 0.007*\"u\" + 0.007*\"getting\"')\n",
      "\n",
      "(1, '0.103*\"giveaway\" + 0.059*\"girl\" + 0.058*\"win\" + 0.058*\"jeep\" + 0.053*\"small\" + 0.053*\"body\" + 0.053*\"sun\" + 0.053*\"cross\" + 0.052*\"chance\" + 0.052*\"entered\"')\n",
      "\n",
      "(2, '0.093*\"jeep\" + 0.035*\"rt\" + 0.014*\"credit\" + 0.013*\"photo\" + 0.013*\"got\" + 0.013*\"day\" + 0.012*\"want\" + 0.011*\"one\" + 0.008*\"kylie\" + 0.008*\"httpstcobvgln4ayie\"')\n",
      "\n",
      "(3, '0.067*\"jeep\" + 0.037*\"wrangler\" + 0.029*\"via\" + 0.021*\"renegade\" + 0.020*\"check\" + 0.019*\"ebay\" + 0.016*\"decal\" + 0.014*\"oracal\" + 0.012*\"graphic\" + 0.012*\"vinyl\"')\n",
      "\n",
      "(4, '0.129*\"jeep\" + 0.093*\"rt\" + 0.020*\"luxbucketlist\" + 0.018*\"jeeplife\" + 0.018*\"need\" + 0.017*\"life\" + 0.016*\"matte\" + 0.013*\"black\" + 0.012*\"better\" + 0.012*\"beep\"')\n",
      "\n",
      "(5, '0.090*\"jeep\" + 0.078*\"rt\" + 0.021*\"jeepporn\" + 0.016*\"compass\" + 0.014*\"make\" + 0.012*\"looking\" + 0.009*\"mean\" + 0.008*\"even\" + 0.008*\"combo\" + 0.008*\"india\"')\n",
      "\n",
      "(6, '0.118*\"jeep\" + 0.050*\"wrangler\" + 0.036*\"cherokee\" + 0.022*\"grand\" + 0.019*\"sport\" + 0.015*\"ebay\" + 0.013*\"unlimited\" + 0.013*\"4x4\" + 0.012*\"2018\" + 0.011*\"2017\"')\n",
      "\n",
      "(7, '0.069*\"jeep\" + 0.019*\"new\" + 0.013*\"rt\" + 0.009*\"car\" + 0.008*\"2018\" + 0.008*\"man\" + 0.008*\"cherokee\" + 0.006*\"speed\" + 0.006*\"ambulance\" + 0.006*\"cant\"')\n",
      "\n",
      "(8, '0.071*\"jeep\" + 0.024*\"rt\" + 0.016*\"dodge\" + 0.015*\"chrysler\" + 0.010*\"top\" + 0.008*\"ram\" + 0.008*\"know\" + 0.007*\"g\" + 0.007*\"u\" + 0.007*\"music\"')\n",
      "\n",
      "(9, '0.086*\"jeep\" + 0.035*\"used\" + 0.032*\"photo\" + 0.029*\"spotted\" + 0.028*\"stick\" + 0.027*\"bamboo\" + 0.027*\"nigeria\" + 0.027*\"hummer\" + 0.027*\"convey\" + 0.022*\"rt\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=10, num_words=10), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF on news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'C://Users//Nick//Documents//Teaching//Data Projects//Text//Webhose//'\n",
    "news_articles = 'news_toyota.pkl'\n",
    "path = directory+news_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_df = pd.read_pickle(directory+news_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawled</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-02T04:24:51.072+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No tra...</td>\n",
       "      <td>Dependable truck 03 Toyota Tacoma Double Cab $1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02T04:27:15.000+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>0 \\nNEW YORK: Automakers reported mixed US car sales in January, with strong demand for SUVs and...</td>\n",
       "      <td>US car sales mixed in January; trucks stay strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-02T04:34:00.008+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>transmission: automatic   2005 Toyota Camry LE 4 door 4 cyl AUTOMATIC VERY CLEAN INSIDE CLOTH IN...</td>\n",
       "      <td>2005 TOYOTA CAMRY LE 167300 MILEAGE $2450 (TALLASSEE) $2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-02T04:36:42.006+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>favorite this post Brand New Toyota Avalon Floor Mats - $115 (New Britain) hide this posting unh...</td>\n",
       "      <td>Brand New Toyota Avalon Floor Mats (New Britain) $115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-02T04:38:24.018+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>more ads by this user QR Code Link to This Post Black w/Piano Black w/Perforated NuLuxe Seat Tri...</td>\n",
       "      <td>2016 Lexus ES 350 (Coliseum Lexus of Oakland) $27772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         crawled language  \\\n",
       "0  2018-02-02T04:24:51.072+02:00  english   \n",
       "1  2018-02-02T04:27:15.000+02:00  english   \n",
       "2  2018-02-02T04:34:00.008+02:00  english   \n",
       "3  2018-02-02T04:36:42.006+02:00  english   \n",
       "4  2018-02-02T04:38:24.018+02:00  english   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No tra...   \n",
       "1  0 \\nNEW YORK: Automakers reported mixed US car sales in January, with strong demand for SUVs and...   \n",
       "2  transmission: automatic   2005 Toyota Camry LE 4 door 4 cyl AUTOMATIC VERY CLEAN INSIDE CLOTH IN...   \n",
       "3  favorite this post Brand New Toyota Avalon Floor Mats - $115 (New Britain) hide this posting unh...   \n",
       "4  more ads by this user QR Code Link to This Post Black w/Piano Black w/Perforated NuLuxe Seat Tri...   \n",
       "\n",
       "                                                         title  \n",
       "0           Dependable truck 03 Toyota Tacoma Double Cab $1500  \n",
       "1            US car sales mixed in January; trucks stay strong  \n",
       "2  2005 TOYOTA CAMRY LE 167300 MILEAGE $2450 (TALLASSEE) $2450  \n",
       "3        Brand New Toyota Avalon Floor Mats (New Britain) $115  \n",
       "4         2016 Lexus ES 350 (Coliseum Lexus of Oakland) $27772  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter non-English tweets\n",
    "news_eng = news_df[news_df['language']=='english'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove special characters to avoid problems with analysis\n",
    "news_eng['text_clean'] = news_eng['text'].map(lambda x: re.sub('[^a-zA-Z0-9 @ . , : - _]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No tra...</td>\n",
       "      <td>QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 \\nNEW YORK: Automakers reported mixed US car sales in January, with strong demand for SUVs and...</td>\n",
       "      <td>0 NEW YORK: Automakers reported mixed US car sales in January, with strong demand for SUVs and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transmission: automatic   2005 Toyota Camry LE 4 door 4 cyl AUTOMATIC VERY CLEAN INSIDE CLOTH IN...</td>\n",
       "      <td>transmission: automatic   2005 Toyota Camry LE 4 door 4 cyl AUTOMATIC VERY CLEAN INSIDE CLOTH IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>favorite this post Brand New Toyota Avalon Floor Mats - $115 (New Britain) hide this posting unh...</td>\n",
       "      <td>favorite this post Brand New Toyota Avalon Floor Mats  115 New Britain hide this posting unhide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more ads by this user QR Code Link to This Post Black w/Piano Black w/Perforated NuLuxe Seat Tri...</td>\n",
       "      <td>more ads by this user QR Code Link to This Post Black wPiano Black wPerforated NuLuxe Seat Trim....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No tra...   \n",
       "1  0 \\nNEW YORK: Automakers reported mixed US car sales in January, with strong demand for SUVs and...   \n",
       "2  transmission: automatic   2005 Toyota Camry LE 4 door 4 cyl AUTOMATIC VERY CLEAN INSIDE CLOTH IN...   \n",
       "3  favorite this post Brand New Toyota Avalon Floor Mats - $115 (New Britain) hide this posting unh...   \n",
       "4  more ads by this user QR Code Link to This Post Black w/Piano Black w/Perforated NuLuxe Seat Tri...   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0  QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No tra...  \n",
       "1  0 NEW YORK: Automakers reported mixed US car sales in January, with strong demand for SUVs and p...  \n",
       "2  transmission: automatic   2005 Toyota Camry LE 4 door 4 cyl AUTOMATIC VERY CLEAN INSIDE CLOTH IN...  \n",
       "3  favorite this post Brand New Toyota Avalon Floor Mats  115 New Britain hide this posting unhide ...  \n",
       "4  more ads by this user QR Code Link to This Post Black wPiano Black wPerforated NuLuxe Seat Trim....  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "news_eng[['text', 'text_clean']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloblist = []\n",
    "del bloblist[:]\n",
    "\n",
    "for i  in range(0,len(news_eng)):\n",
    "    bloblist.append(TextBlob(news_eng['text_clean'].iloc[i]))\n",
    "    \n",
    "len(bloblist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in news article 1\n",
      "\tWord: receipts, TF-IDF: 0.21733\n",
      "\tWord: Cash, TF-IDF: 0.21733\n",
      "\tWord: 6477478013, TF-IDF: 0.21733\n",
      "\tWord: sale, TF-IDF: 0.19481\n",
      "\tWord: maintenance, TF-IDF: 0.17883\n",
      "\tWord: owner, TF-IDF: 0.17883\n",
      "\tWord: available, TF-IDF: 0.16643\n",
      "\tWord: trades, TF-IDF: 0.1563\n",
      "\tWord: truck, TF-IDF: 0.11779\n",
      "\tWord: Code, TF-IDF: 0.09844\n",
      "Top words in news article 2\n",
      "\tWord: And, TF-IDF: 0.06643\n",
      "\tWord: In, TF-IDF: 0.05853\n",
      "\tWord: sales, TF-IDF: 0.04664\n",
      "\tWord: US, TF-IDF: 0.02365\n",
      "\tWord: The, TF-IDF: 0.02218\n",
      "\tWord: pickup, TF-IDF: 0.02214\n",
      "\tWord: saw, TF-IDF: 0.02117\n",
      "\tWord: strong, TF-IDF: 0.02106\n",
      "\tWord: percent, TF-IDF: 0.01984\n",
      "\tWord: overall, TF-IDF: 0.0195\n",
      "Top words in news article 3\n",
      "\tWord: AUTOMATIC, TF-IDF: 0.18935\n",
      "\tWord: automatic, TF-IDF: 0.15643\n",
      "\tWord: Just, TF-IDF: 0.11506\n",
      "\tWord: 167300, TF-IDF: 0.11506\n",
      "\tWord: Little, TF-IDF: 0.11506\n",
      "\tWord: 6473894894, TF-IDF: 0.11506\n",
      "\tWord: LE, TF-IDF: 0.11506\n",
      "\tWord: cyl, TF-IDF: 0.11506\n",
      "\tWord: 2450, TF-IDF: 0.11506\n",
      "\tWord: Hale, TF-IDF: 0.11506\n",
      "Top words in news article 4\n",
      "\tWord: mats, TF-IDF: 0.13336\n",
      "\tWord: Mats, TF-IDF: 0.13336\n",
      "\tWord: Floor, TF-IDF: 0.08891\n",
      "\tWord: floor, TF-IDF: 0.07969\n",
      "\tWord: Avalon, TF-IDF: 0.06394\n",
      "\tWord: Post, TF-IDF: 0.05846\n",
      "\tWord: original, TF-IDF: 0.0574\n",
      "\tWord: These, TF-IDF: 0.05233\n",
      "\tWord: post, TF-IDF: 0.04592\n",
      "\tWord: Brand, TF-IDF: 0.04445\n",
      "Top words in news article 5\n",
      "\tWord: included, TF-IDF: 0.0788\n",
      "\tWord: Black, TF-IDF: 0.06732\n",
      "\tWord: Lexus, TF-IDF: 0.06177\n",
      "\tWord: below, TF-IDF: 0.05174\n",
      "\tWord: OneOwner, TF-IDF: 0.04396\n",
      "\tWord: synthetic, TF-IDF: 0.04396\n",
      "\tWord: Fair, TF-IDF: 0.04396\n",
      "\tWord: user, TF-IDF: 0.04396\n",
      "\tWord: Purchase, TF-IDF: 0.04396\n",
      "\tWord: 3121, TF-IDF: 0.04396\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(bloblist):\n",
    "# Print top 5 values\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"Top words in news article {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LDA to news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QR Code Link to This Post All maintenance receipts available, one owner truck. Cash sale. No trades.   6477478013']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list = news_eng['text_clean'].tolist()\n",
    "news_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_clean = [clean(doc).split() for doc in news_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qr', 'code', 'link', 'post', 'maintenance', 'receipt', 'available', 'one', 'owner', 'truck', 'cash', 'sale', 'trade', '6477478013']\n"
     ]
    }
   ],
   "source": [
    "print(*news_clean[:1], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 ms\n"
     ]
    }
   ],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "\n",
    "dictionary = corpora.Dictionary(news_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "\n",
    "%time doc_term_matrix = [dictionary.doc2bow(doc) for doc in news_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "numtopics = 3\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "%time ldamodel = Lda(doc_term_matrix, num_topics=numtopics, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.017*\"toyota\" + 0.010*\"vehicle\" + 0.009*\"car\"')\n",
      "\n",
      "(1, '0.010*\"ford\" + 0.008*\"toyota\" + 0.007*\"sale\"')\n",
      "\n",
      "(2, '0.026*\"percent\" + 0.021*\"u\" + 0.012*\"earnings\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=3), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.017*\"toyota\" + 0.010*\"vehicle\" + 0.009*\"car\" + 0.007*\"sale\" + 0.007*\"year\"')\n",
      "\n",
      "(1, '0.010*\"ford\" + 0.008*\"toyota\" + 0.007*\"sale\" + 0.006*\"said\" + 0.005*\"company\"')\n",
      "\n",
      "(2, '0.026*\"percent\" + 0.021*\"u\" + 0.012*\"earnings\" + 0.012*\"yield\" + 0.011*\"index\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=5), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.017*\"toyota\" + 0.010*\"vehicle\" + 0.009*\"car\" + 0.007*\"sale\" + 0.007*\"year\" + 0.006*\"new\" + 0.006*\"market\"')\n",
      "\n",
      "(1, '0.010*\"ford\" + 0.008*\"toyota\" + 0.007*\"sale\" + 0.006*\"said\" + 0.005*\"company\" + 0.005*\"percent\" + 0.004*\"hydrogen\"')\n",
      "\n",
      "(2, '0.026*\"percent\" + 0.021*\"u\" + 0.012*\"earnings\" + 0.012*\"yield\" + 0.011*\"index\" + 0.009*\"share\" + 0.009*\"lower\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=7), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.017*\"toyota\" + 0.010*\"vehicle\" + 0.009*\"car\" + 0.007*\"sale\" + 0.007*\"year\" + 0.006*\"new\" + 0.006*\"market\" + 0.005*\"unit\" + 0.005*\"january\" + 0.004*\"per\"')\n",
      "\n",
      "(1, '0.010*\"ford\" + 0.008*\"toyota\" + 0.007*\"sale\" + 0.006*\"said\" + 0.005*\"company\" + 0.005*\"percent\" + 0.004*\"hydrogen\" + 0.004*\"2018\" + 0.004*\"vehicle\" + 0.004*\"year\"')\n",
      "\n",
      "(2, '0.026*\"percent\" + 0.021*\"u\" + 0.012*\"earnings\" + 0.012*\"yield\" + 0.011*\"index\" + 0.009*\"share\" + 0.009*\"lower\" + 0.009*\"cent\" + 0.009*\"per\" + 0.009*\"investor\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=10), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "numtopics = 5\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "%time ldamodel = Lda(doc_term_matrix, num_topics=numtopics, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"percent\" + 0.018*\"sale\" + 0.014*\"toyota\"')\n",
      "\n",
      "(1, '0.014*\"toyota\" + 0.011*\"ford\" + 0.009*\"car\"')\n",
      "\n",
      "(2, '0.009*\"company\" + 0.006*\"toyota\" + 0.006*\"state\"')\n",
      "\n",
      "(3, '0.014*\"toyota\" + 0.008*\"car\" + 0.007*\"post\"')\n",
      "\n",
      "(4, '0.023*\"u\" + 0.019*\"percent\" + 0.014*\"earnings\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=3), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"percent\" + 0.018*\"sale\" + 0.014*\"toyota\" + 0.012*\"vehicle\" + 0.010*\"year\"')\n",
      "\n",
      "(1, '0.014*\"toyota\" + 0.011*\"ford\" + 0.009*\"car\" + 0.009*\"market\" + 0.009*\"unit\"')\n",
      "\n",
      "(2, '0.009*\"company\" + 0.006*\"toyota\" + 0.006*\"state\" + 0.006*\"workforce\" + 0.005*\"job\"')\n",
      "\n",
      "(3, '0.014*\"toyota\" + 0.008*\"car\" + 0.007*\"post\" + 0.007*\"japan\" + 0.006*\"hydrogen\"')\n",
      "\n",
      "(4, '0.023*\"u\" + 0.019*\"percent\" + 0.014*\"earnings\" + 0.014*\"yield\" + 0.012*\"index\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=5), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"percent\" + 0.018*\"sale\" + 0.014*\"toyota\" + 0.012*\"vehicle\" + 0.010*\"year\" + 0.006*\"january\" + 0.006*\"market\"')\n",
      "\n",
      "(1, '0.014*\"toyota\" + 0.011*\"ford\" + 0.009*\"car\" + 0.009*\"market\" + 0.009*\"unit\" + 0.007*\"vehicle\" + 0.007*\"year\"')\n",
      "\n",
      "(2, '0.009*\"company\" + 0.006*\"toyota\" + 0.006*\"state\" + 0.006*\"workforce\" + 0.005*\"job\" + 0.005*\"law\" + 0.005*\"alabama\"')\n",
      "\n",
      "(3, '0.014*\"toyota\" + 0.008*\"car\" + 0.007*\"post\" + 0.007*\"japan\" + 0.006*\"hydrogen\" + 0.006*\"new\" + 0.005*\"australia\"')\n",
      "\n",
      "(4, '0.023*\"u\" + 0.019*\"percent\" + 0.014*\"earnings\" + 0.014*\"yield\" + 0.012*\"index\" + 0.011*\"share\" + 0.010*\"cent\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=7), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"percent\" + 0.018*\"sale\" + 0.014*\"toyota\" + 0.012*\"vehicle\" + 0.010*\"year\" + 0.006*\"january\" + 0.006*\"market\" + 0.004*\"1\" + 0.004*\"said\" + 0.004*\"u\"')\n",
      "\n",
      "(1, '0.014*\"toyota\" + 0.011*\"ford\" + 0.009*\"car\" + 0.009*\"market\" + 0.009*\"unit\" + 0.007*\"vehicle\" + 0.007*\"year\" + 0.007*\"january\" + 0.006*\"per\" + 0.006*\"2018\"')\n",
      "\n",
      "(2, '0.009*\"company\" + 0.006*\"toyota\" + 0.006*\"state\" + 0.006*\"workforce\" + 0.005*\"job\" + 0.005*\"law\" + 0.005*\"alabama\" + 0.005*\"said\" + 0.005*\"ball\" + 0.004*\"player\"')\n",
      "\n",
      "(3, '0.014*\"toyota\" + 0.008*\"car\" + 0.007*\"post\" + 0.007*\"japan\" + 0.006*\"hydrogen\" + 0.006*\"new\" + 0.005*\"australia\" + 0.005*\"contact\" + 0.005*\"also\" + 0.004*\"offer\"')\n",
      "\n",
      "(4, '0.023*\"u\" + 0.019*\"percent\" + 0.014*\"earnings\" + 0.014*\"yield\" + 0.012*\"index\" + 0.011*\"share\" + 0.010*\"cent\" + 0.010*\"lower\" + 0.010*\"investor\" + 0.010*\"per\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=10), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"percent\" + 0.018*\"sale\" + 0.014*\"toyota\" + 0.012*\"vehicle\" + 0.010*\"year\" + 0.006*\"january\" + 0.006*\"market\" + 0.004*\"1\" + 0.004*\"said\" + 0.004*\"u\"')\n",
      "\n",
      "(1, '0.014*\"toyota\" + 0.011*\"ford\" + 0.009*\"car\" + 0.009*\"market\" + 0.009*\"unit\" + 0.007*\"vehicle\" + 0.007*\"year\" + 0.007*\"january\" + 0.006*\"per\" + 0.006*\"2018\"')\n",
      "\n",
      "(2, '0.009*\"company\" + 0.006*\"toyota\" + 0.006*\"state\" + 0.006*\"workforce\" + 0.005*\"job\" + 0.005*\"law\" + 0.005*\"alabama\" + 0.005*\"said\" + 0.005*\"ball\" + 0.004*\"player\"')\n",
      "\n",
      "(3, '0.014*\"toyota\" + 0.008*\"car\" + 0.007*\"post\" + 0.007*\"japan\" + 0.006*\"hydrogen\" + 0.006*\"new\" + 0.005*\"australia\" + 0.005*\"contact\" + 0.005*\"also\" + 0.004*\"offer\"')\n",
      "\n",
      "(4, '0.023*\"u\" + 0.019*\"percent\" + 0.014*\"earnings\" + 0.014*\"yield\" + 0.012*\"index\" + 0.011*\"share\" + 0.010*\"cent\" + 0.010*\"lower\" + 0.010*\"investor\" + 0.010*\"per\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=10), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "numtopics = 10\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "%time ldamodel = Lda(doc_term_matrix, num_topics=numtopics, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.013*\"toyota\" + 0.009*\"air\" + 0.008*\"bag\"')\n",
      "\n",
      "(1, '0.046*\"percent\" + 0.018*\"sale\" + 0.011*\"year\"')\n",
      "\n",
      "(2, '0.030*\"unit\" + 0.023*\"market\" + 0.018*\"january\"')\n",
      "\n",
      "(3, '0.018*\"toyota\" + 0.017*\"car\" + 0.013*\"vehicle\"')\n",
      "\n",
      "(4, '0.008*\"post\" + 0.008*\"toyota\" + 0.006*\"lexus\"')\n",
      "\n",
      "(5, '0.014*\"hydrogen\" + 0.011*\"company\" + 0.011*\"australia\"')\n",
      "\n",
      "(6, '0.020*\"ford\" + 0.018*\"toyota\" + 0.011*\"japan\"')\n",
      "\n",
      "(7, '0.013*\"car\" + 0.012*\"toyota\" + 0.009*\"post\"')\n",
      "\n",
      "(8, '0.013*\"per\" + 0.013*\"cent\" + 0.010*\"toyota\"')\n",
      "\n",
      "(9, '0.026*\"u\" + 0.018*\"percent\" + 0.015*\"earnings\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=3), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.013*\"toyota\" + 0.009*\"air\" + 0.008*\"bag\" + 0.008*\"year\" + 0.007*\"commercial\"')\n",
      "\n",
      "(1, '0.046*\"percent\" + 0.018*\"sale\" + 0.011*\"year\" + 0.010*\"january\" + 0.009*\"market\"')\n",
      "\n",
      "(2, '0.030*\"unit\" + 0.023*\"market\" + 0.018*\"january\" + 0.017*\"toyota\" + 0.014*\"vehicle\"')\n",
      "\n",
      "(3, '0.018*\"toyota\" + 0.017*\"car\" + 0.013*\"vehicle\" + 0.009*\"2018\" + 0.007*\"release\"')\n",
      "\n",
      "(4, '0.008*\"post\" + 0.008*\"toyota\" + 0.006*\"lexus\" + 0.005*\"contact\" + 0.005*\"lx\"')\n",
      "\n",
      "(5, '0.014*\"hydrogen\" + 0.011*\"company\" + 0.011*\"australia\" + 0.010*\"state\" + 0.010*\"workforce\"')\n",
      "\n",
      "(6, '0.020*\"ford\" + 0.018*\"toyota\" + 0.011*\"japan\" + 0.010*\"vehicle\" + 0.007*\"margin\"')\n",
      "\n",
      "(7, '0.013*\"car\" + 0.012*\"toyota\" + 0.009*\"post\" + 0.007*\"d\" + 0.007*\"contact\"')\n",
      "\n",
      "(8, '0.013*\"per\" + 0.013*\"cent\" + 0.010*\"toyota\" + 0.009*\"law\" + 0.008*\"ball\"')\n",
      "\n",
      "(9, '0.026*\"u\" + 0.018*\"percent\" + 0.015*\"earnings\" + 0.015*\"yield\" + 0.012*\"index\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=5), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.013*\"toyota\" + 0.009*\"air\" + 0.008*\"bag\" + 0.008*\"year\" + 0.007*\"commercial\" + 0.007*\"lexus\" + 0.006*\"could\"')\n",
      "\n",
      "(1, '0.046*\"percent\" + 0.018*\"sale\" + 0.011*\"year\" + 0.010*\"january\" + 0.009*\"market\" + 0.007*\"increase\" + 0.007*\"said\"')\n",
      "\n",
      "(2, '0.030*\"unit\" + 0.023*\"market\" + 0.018*\"january\" + 0.017*\"toyota\" + 0.014*\"vehicle\" + 0.013*\"new\" + 0.012*\"2018\"')\n",
      "\n",
      "(3, '0.018*\"toyota\" + 0.017*\"car\" + 0.013*\"vehicle\" + 0.009*\"2018\" + 0.007*\"release\" + 0.007*\"review\" + 0.007*\"news\"')\n",
      "\n",
      "(4, '0.008*\"post\" + 0.008*\"toyota\" + 0.006*\"lexus\" + 0.005*\"contact\" + 0.005*\"lx\" + 0.003*\"qr\" + 0.003*\"code\"')\n",
      "\n",
      "(5, '0.014*\"hydrogen\" + 0.011*\"company\" + 0.011*\"australia\" + 0.010*\"state\" + 0.010*\"workforce\" + 0.010*\"job\" + 0.010*\"alabama\"')\n",
      "\n",
      "(6, '0.020*\"ford\" + 0.018*\"toyota\" + 0.011*\"japan\" + 0.010*\"vehicle\" + 0.007*\"margin\" + 0.007*\"one\" + 0.007*\"year\"')\n",
      "\n",
      "(7, '0.013*\"car\" + 0.012*\"toyota\" + 0.009*\"post\" + 0.007*\"d\" + 0.007*\"contact\" + 0.007*\"new\" + 0.006*\"offer\"')\n",
      "\n",
      "(8, '0.013*\"per\" + 0.013*\"cent\" + 0.010*\"toyota\" + 0.009*\"law\" + 0.008*\"ball\" + 0.008*\"sale\" + 0.008*\"car\"')\n",
      "\n",
      "(9, '0.026*\"u\" + 0.018*\"percent\" + 0.015*\"earnings\" + 0.015*\"yield\" + 0.012*\"index\" + 0.012*\"share\" + 0.011*\"cent\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=7), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.013*\"toyota\" + 0.009*\"air\" + 0.008*\"bag\" + 0.008*\"year\" + 0.007*\"commercial\" + 0.007*\"lexus\" + 0.006*\"could\" + 0.005*\"game\" + 0.005*\"owner\" + 0.005*\"motor\"')\n",
      "\n",
      "(1, '0.046*\"percent\" + 0.018*\"sale\" + 0.011*\"year\" + 0.010*\"january\" + 0.009*\"market\" + 0.007*\"increase\" + 0.007*\"said\" + 0.006*\"u\" + 0.006*\"month\" + 0.006*\"export\"')\n",
      "\n",
      "(2, '0.030*\"unit\" + 0.023*\"market\" + 0.018*\"january\" + 0.017*\"toyota\" + 0.014*\"vehicle\" + 0.013*\"new\" + 0.012*\"2018\" + 0.011*\"per\" + 0.011*\"cent\" + 0.011*\"share\"')\n",
      "\n",
      "(3, '0.018*\"toyota\" + 0.017*\"car\" + 0.013*\"vehicle\" + 0.009*\"2018\" + 0.007*\"release\" + 0.007*\"review\" + 0.007*\"news\" + 0.007*\"sale\" + 0.006*\"electrified\" + 0.006*\"company\"')\n",
      "\n",
      "(4, '0.008*\"post\" + 0.008*\"toyota\" + 0.006*\"lexus\" + 0.005*\"contact\" + 0.005*\"lx\" + 0.003*\"qr\" + 0.003*\"code\" + 0.003*\"link\" + 0.003*\"truck\" + 0.003*\"service\"')\n",
      "\n",
      "(5, '0.014*\"hydrogen\" + 0.011*\"company\" + 0.011*\"australia\" + 0.010*\"state\" + 0.010*\"workforce\" + 0.010*\"job\" + 0.010*\"alabama\" + 0.009*\"said\" + 0.007*\"industry\" + 0.006*\"need\"')\n",
      "\n",
      "(6, '0.020*\"ford\" + 0.018*\"toyota\" + 0.011*\"japan\" + 0.010*\"vehicle\" + 0.007*\"margin\" + 0.007*\"one\" + 0.007*\"year\" + 0.006*\"commodity\" + 0.006*\"canada\" + 0.005*\"said\"')\n",
      "\n",
      "(7, '0.013*\"car\" + 0.012*\"toyota\" + 0.009*\"post\" + 0.007*\"d\" + 0.007*\"contact\" + 0.007*\"new\" + 0.006*\"offer\" + 0.005*\"service\" + 0.005*\"id\" + 0.005*\"unsolicited\"')\n",
      "\n",
      "(8, '0.013*\"per\" + 0.013*\"cent\" + 0.010*\"toyota\" + 0.009*\"law\" + 0.008*\"ball\" + 0.008*\"sale\" + 0.008*\"car\" + 0.008*\"player\" + 0.006*\"man\" + 0.006*\"f1\"')\n",
      "\n",
      "(9, '0.026*\"u\" + 0.018*\"percent\" + 0.015*\"earnings\" + 0.015*\"yield\" + 0.012*\"index\" + 0.012*\"share\" + 0.011*\"cent\" + 0.011*\"investor\" + 0.011*\"per\" + 0.011*\"benchmark\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=10), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.013*\"toyota\" + 0.009*\"air\" + 0.008*\"bag\" + 0.008*\"year\" + 0.007*\"commercial\" + 0.007*\"lexus\" + 0.006*\"could\" + 0.005*\"game\" + 0.005*\"owner\" + 0.005*\"motor\"')\n",
      "\n",
      "(1, '0.046*\"percent\" + 0.018*\"sale\" + 0.011*\"year\" + 0.010*\"january\" + 0.009*\"market\" + 0.007*\"increase\" + 0.007*\"said\" + 0.006*\"u\" + 0.006*\"month\" + 0.006*\"export\"')\n",
      "\n",
      "(2, '0.030*\"unit\" + 0.023*\"market\" + 0.018*\"january\" + 0.017*\"toyota\" + 0.014*\"vehicle\" + 0.013*\"new\" + 0.012*\"2018\" + 0.011*\"per\" + 0.011*\"cent\" + 0.011*\"share\"')\n",
      "\n",
      "(3, '0.018*\"toyota\" + 0.017*\"car\" + 0.013*\"vehicle\" + 0.009*\"2018\" + 0.007*\"release\" + 0.007*\"review\" + 0.007*\"news\" + 0.007*\"sale\" + 0.006*\"electrified\" + 0.006*\"company\"')\n",
      "\n",
      "(4, '0.008*\"post\" + 0.008*\"toyota\" + 0.006*\"lexus\" + 0.005*\"contact\" + 0.005*\"lx\" + 0.003*\"qr\" + 0.003*\"code\" + 0.003*\"link\" + 0.003*\"truck\" + 0.003*\"service\"')\n",
      "\n",
      "(5, '0.014*\"hydrogen\" + 0.011*\"company\" + 0.011*\"australia\" + 0.010*\"state\" + 0.010*\"workforce\" + 0.010*\"job\" + 0.010*\"alabama\" + 0.009*\"said\" + 0.007*\"industry\" + 0.006*\"need\"')\n",
      "\n",
      "(6, '0.020*\"ford\" + 0.018*\"toyota\" + 0.011*\"japan\" + 0.010*\"vehicle\" + 0.007*\"margin\" + 0.007*\"one\" + 0.007*\"year\" + 0.006*\"commodity\" + 0.006*\"canada\" + 0.005*\"said\"')\n",
      "\n",
      "(7, '0.013*\"car\" + 0.012*\"toyota\" + 0.009*\"post\" + 0.007*\"d\" + 0.007*\"contact\" + 0.007*\"new\" + 0.006*\"offer\" + 0.005*\"service\" + 0.005*\"id\" + 0.005*\"unsolicited\"')\n",
      "\n",
      "(8, '0.013*\"per\" + 0.013*\"cent\" + 0.010*\"toyota\" + 0.009*\"law\" + 0.008*\"ball\" + 0.008*\"sale\" + 0.008*\"car\" + 0.008*\"player\" + 0.006*\"man\" + 0.006*\"f1\"')\n",
      "\n",
      "(9, '0.026*\"u\" + 0.018*\"percent\" + 0.015*\"earnings\" + 0.015*\"yield\" + 0.012*\"index\" + 0.012*\"share\" + 0.011*\"cent\" + 0.011*\"investor\" + 0.011*\"per\" + 0.011*\"benchmark\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel.print_topics(num_topics=numtopics, num_words=10), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
